"""
Functions that load data.
"""

from __future__ import annotations

import json
import h5py
import random
import warnings
import numpy as np
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor
from pymatgen.entries.computed_entries import ComputedStructureEntry

import torch
import torch_geometric

def parse_cse_entry(file_path: str) -> ComputedStructureEntry:
    """
    Parses a single JSON file that contains a pymatgen ComputedStructureEntry.
    Input:
        file_path:          Valid file path to a JSON file
    Output:
        cse_data:           pymatgen ComputedStructureEntry
    """
    with open(file_path, "r") as file:
        json_dict = json.load(file)
    cse = ComputedStructureEntry.from_dict(json_dict)
    return cse

def parallel_parse_cse_entries(file_path_list: list[str]) -> list[ComputedStructureEntry]:
    """
    Parses all JSON files in parallel from a list of file paths.
    Input:
        file_path_list:     List of valid file paths to JSON files
    Output:
        cse_data:           List containing pymatgen ComputedStructureEntries
    """
    with ProcessPoolExecutor() as executor:
        cse_data = list(tqdm(executor.map(parse_cse_entry, file_path_list), desc="Parallel parsing of JSON files"))
    return cse_data

def parse_h5_file(file_path: str) -> list[dict]:
    """
    Parses a single h5 file and converts the data into a dictionary.
    Input:
        file_path:          Path to a h5 file
    Output:
        data_list:          List of dictionaries
    """
    with h5py.File(file_path, "r") as f:
        data_list = []
        keys = list(f.keys())
        for key in tqdm(keys, desc=f"Loading data from {file_path:s}"):            
            data_list.append({subkey: np.array(value) for subkey, value in f[key].items()})
    return data_list

def load_torch_data(data_path: str) -> dict:
    """
    Loads data from the specified path using torch.
    Input:
        data_path:          For example, a path to a file generated by 'research/db_init.py'
    Output:
        data:               Some "data object", which can be anything, so be careful with this function
                            (but it will probably end up being a dictionary....)
    """
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        data = torch.load(data_path, weights_only=False)
    return data

def create_dataloader(
    data_list: list,
    num_data: int = -1,
    batch_size: int = 32,
    shuffle: bool = False,
    seed: int = 42,
) -> torch_geometric.loader.DataLoader:
    """
    Creates a torch_geometric dataloader based on a list of graphs.
    Input:
        data_list:      List of graphs, see 'research/db_init.py'
        num_data:       Number of samples to use in the dataset (any number < 1 uses all data points)
        batch_size:     Batch size
        shuffle:        Flag to enable shuffling of data
        seed:           Random seed (only used if 'shuffle=True')
    Output:
        dataloader:     Dataloader object
    """ 
    # ensure reproducibility when shuffling
    generator = torch.Generator()
    generator.manual_seed(seed)
    
    # optionally specify the number of data points
    total = len(data_list)
    if 0 < num_data < total:
        rng = random.Random(42) # fixed subsets
        subset = rng.sample(data_list, k=num_data) # no in-place modification of the original list
    else:
        subset = data_list # use the whole list
        
    # create a dataloader
    dataloader = torch_geometric.loader.DataLoader(
        subset,
        batch_size=batch_size,
        shuffle=shuffle,
        generator=generator,
        follow_batch=["edge_index", "threebody_index"],
    )
    return dataloader